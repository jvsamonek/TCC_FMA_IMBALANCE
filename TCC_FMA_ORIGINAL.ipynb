{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC-FMA-ORIGINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qLiaFkKoMIkH"
      ],
      "authorship_tag": "ABX9TyP06EYYlQhmvbRK8Le4tMeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvsamonek/TCC_FMA_IMBALANCE/blob/main/TCC_FMA_ORIGINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yug2XT0Dh252"
      },
      "source": [
        "#Iniciador de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2pDpPNLFt6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a378003d-4ea3-40d9-c71f-c166244317da"
      },
      "source": [
        "#!ls \"drive/My Drive/TCC/fma90k/ARFFs\"\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "import re \n",
        "import numpy as np\n",
        "import os\n",
        "import itertools\n",
        "import collections\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "!pip install scikit-multilearn\n",
        "from skmultilearn.ensemble import RakelO\n",
        "import sklearn.metrics as metrics\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from tempfile import TemporaryFile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.6/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLiaFkKoMIkH"
      },
      "source": [
        "# Declaração de funções de apoio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_enK-khWUSvH"
      },
      "source": [
        "#classe para validação\n",
        "\"\"\"Classe de validador da base, que possui funções para retornar a média de balanceamento da base.\n",
        "\"\"\"\n",
        "class validatorB:\n",
        "  def __init__(self):\n",
        "    self.y = np.array([])\n",
        "    self.full_label_set = []\n",
        "    self.labels = []\n",
        "\n",
        "  def sum_h(self,l): \n",
        "    h_sum=0\n",
        "    for label_set in self.y: \n",
        "      if(label_set[l] == 1):\n",
        "        h_sum += 1\n",
        "    return h_sum \n",
        "\n",
        "  def get_imbalance_ratio_per_label(self,l):\n",
        "    sum_array=list(map(self.sum_h,self.full_label_set))\n",
        "    sum_array=np.array(sum_array)\n",
        "    return sum_array.max()/self.sum_h(l)\n",
        "\n",
        "  def meanIR(self,y,D):\n",
        "    self.y = y.toarray()\n",
        "    _, self.labels = getCaracteristicas(D)\n",
        "    self.full_label_set = np.arange(len(labels))\n",
        "    ratio_sum=np.sum(np.array(list(map(self.get_imbalance_ratio_per_label,self.full_label_set))))\n",
        "    return ratio_sum/self.full_label_set.shape[0]\n",
        "\n",
        "#Funçoes de apoio\n",
        "\n",
        "\"\"\"Retorna features da base.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "\"\"\"\n",
        "def getCaracteristicas(D):\n",
        "  listOfColumns = D.columns.to_list()\n",
        "  r = re.compile(\"feature.*\")\n",
        "  #r = re.compile(\"[A-Z].*\")\n",
        "  features = list(filter(r.match, listOfColumns)) # Read Note\n",
        "  labels = (list(set(listOfColumns) - set(features)))\n",
        "  return features, labels\n",
        "\n",
        "\"\"\"Retorna cardinalidade de rótulo da base.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "\"\"\"\n",
        "def cardinalidadeDeRotulo(D):\n",
        "  sizeYi = 0\n",
        "  N = D.shape[0]\n",
        "  features, labels = getCaracteristicas(D)\n",
        "  auxD = D[:][labels].values\n",
        "  for i in auxD:\n",
        "    sizeYi += np.count_nonzero(i == 1)\n",
        "  return (1/N) * sizeYi\n",
        "\n",
        "\"\"\"Retorna densidade de rótulo da base.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "\"\"\"\n",
        "def densidadeDeRotulo(D):\n",
        "  sizeYi = 0\n",
        "  N = D.shape[0]\n",
        "  features, labels = getCaracteristicas(D)\n",
        "  Nr = len(labels)\n",
        "  auxD = D[:][labels].values\n",
        "  for i in auxD:#range(0, D.shape[0]):\n",
        "    sizeYi += np.count_nonzero(i == 1)/Nr#(df.iloc[[i]][labels].values == b'1')/Nr\n",
        "  return (1/N) * sizeYi\n",
        "\n",
        "\n",
        "\"\"\"Retorna hamming loss da predição, partindo das predições retornadas por um classificador.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "predictions = saída do classíficador\n",
        "y_test = resultados reais\n",
        "\"\"\"\n",
        "def hammingLoss(D, predictions, y_test):\n",
        "  sumHL = 0\n",
        "  N = predictions.shape[0]\n",
        "  features, labels = getCaracteristicas(D)\n",
        "  Nr = len(labels)\n",
        "  for i in range(0, predictions.shape[0]):\n",
        "    a = predictions[i].astype(int)\n",
        "    b = y_test[i].toarray().astype(int)\n",
        "    c = csr_matrix(np.bitwise_xor(a, b))\n",
        "    tamanhoDaDiferenca = np.count_nonzero(c.toarray() == 1)\n",
        "    sumHL += tamanhoDaDiferenca/Nr\n",
        "  return (1/N) * sumHL\n",
        "\n",
        "\"\"\"Retorna acuracia da predição, partindo das predições retornadas por um classificador.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "predictions = saída do classíficador\n",
        "y_test = resultados reais\n",
        "\"\"\"\n",
        "def acuracia(D, predictions, y_test):\n",
        "  cum = 0\n",
        "  N = predictions.shape[0]\n",
        "  features, labels = getCaracteristicas(D)\n",
        "  Nr = len(labels)\n",
        "  for i in range(0, predictions.shape[0]):\n",
        "    a = predictions[i].astype(int)\n",
        "    b = y_test[i].toarray().astype(int)\n",
        "    union = np.count_nonzero(csr_matrix(np.bitwise_or(a, b)).toarray() == 1)\n",
        "    inter = np.count_nonzero(csr_matrix(np.bitwise_and(a, b)).toarray() == 1)\n",
        "    cum += inter/union\n",
        "  return (1/N) * cum\n",
        "\n",
        "\"\"\"Retorna precisao da predição, partindo das predições retornadas por um classificador.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "predictions = saída do classíficador\n",
        "y_test = resultados reais\n",
        "\"\"\"\n",
        "def precisao(D, predictions, y_test):\n",
        "  cum = 0\n",
        "  N = predictions.shape[0]\n",
        "  features, labels = getCaracteristicas(D)\n",
        "  Nr = len(labels)\n",
        "  for i in range(0, predictions.shape[0]):\n",
        "    a = predictions[i].astype(int)\n",
        "    b = y_test[i].toarray().astype(int)\n",
        "    Ri = np.count_nonzero(a == 1)\n",
        "    inter = np.count_nonzero(csr_matrix(np.bitwise_and(a, b)).toarray() == 1)\n",
        "    if(Ri>0):\n",
        "      cum += inter/Ri\n",
        "    else:\n",
        "      cum += 0\n",
        "  return (1/N) * cum\n",
        "\n",
        "#Funçoes para manter base\n",
        "\"\"\"Retira instâncias com generos de pouca relevãncia, retornando um dataframe reamostrado e rótulos restantes.\n",
        "\n",
        "Entradas:\n",
        "N = Quantidade minima que cada classe deve ter de instâncias\n",
        "DF = Dataframe com a base completa \n",
        "\"\"\"\n",
        "def dropGenresWithLessThan(N, DF):\n",
        "  genre_ranking = {}\n",
        "  for genre in DF[labels].columns:\n",
        "    genre_ranking[genre] = 0\n",
        "    for track in DF[genre].values:\n",
        "      if(track == 1):\n",
        "        genre_ranking[genre] = genre_ranking[genre] + 1\n",
        "  tuples_genre_ranking = sorted(genre_ranking.items(), key=lambda x: x[1], reverse=True)\n",
        "  while(True):\n",
        "    if(tuples_genre_ranking[-1][1] < N):\n",
        "      to_drop = DF[DF[tuples_genre_ranking[-1][0]] != 0]\n",
        "      DF = DF.drop(to_drop.index)\n",
        "      #print(to_drop)\n",
        "      DF = DF.drop(columns=[tuples_genre_ranking[-1][0]])\n",
        "      \n",
        "      #print('removendo: '+ tuples_genre_ranking[-1][0])\n",
        "      labels.remove(tuples_genre_ranking[-1][0])\n",
        "      tuples_genre_ranking = tuples_genre_ranking[:-1]\n",
        "    else:\n",
        "      break\n",
        "  print(labels)\n",
        "  return DF, labels\n",
        "\n",
        "  #metricas\n",
        "\n",
        "\"\"\"Mostra na tela métricas obtidas com base no sciKit.\n",
        "\n",
        "Entradas:\n",
        "predictions = saída do classíficador\n",
        "y_test = resultados reais\n",
        "\"\"\"\n",
        "def sciMetricas(y_test, predictions):\n",
        "  print(\"Metrica do pacote do sklearn:\")\n",
        "  #part_acc=metrics.accuracy_score(y_test, predictions)\n",
        "  part_prec=metrics.precision_score(y_test, predictions, average = 'micro')\n",
        "  #part_recall=metrics.recall_score(y_test, predictions, average = 'micro')\n",
        "  #part_hamm=metrics.hamming_loss(y_test,predictions)\n",
        "  #print('Classifier accuracy score:',round(part_acc,3))\n",
        "  print('Classifier precision score:',round(part_prec,3))\n",
        "  #print('Classifier recall score:',round(part_recall,3))\n",
        "  #print('Classifier Hamming Loss:',round(part_hamm,3))\n",
        "\n",
        "\"\"\"Mostra na tela métricas obtidas com base no desenvolvido para o projeto.\n",
        "\n",
        "Entradas:\n",
        "predictions = saída do classíficador\n",
        "y_test = resultados reais\n",
        "\"\"\"\n",
        "def minhasMetricas(df, y_test, predictions):\n",
        "  print(\"Metrica exposta na proposta:\")\n",
        "  #part_acc=acuracia(df, predictions, y_test)#metrics.accuracy_score(y_test, predictions)\n",
        "  part_prec=precisao(df, predictions, y_test)#metrics.precision_score(y_test, predictions, average = 'micro')\n",
        "\n",
        "  #part_recall=metrics.recall_score(y_test, predictions, average = 'micro')\n",
        "\n",
        "  #part_hamm=hammingLoss(df, predictions, y_test)#metrics.hamming_loss(y_test,predictions)\n",
        "  #print('Classifier accuracy score:',round(part_acc,3))\n",
        "  print('Classifier precision score:',round(part_prec,3))\n",
        "  #print('Classifier recall score:',round(part_recall,3))\n",
        "  #print('Classifier Hamming Loss:',round(part_hamm,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gig-eDTqaGZH"
      },
      "source": [
        "# Declaração de algoritmos de Balanceamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J3ufIXntipv"
      },
      "source": [
        "MLROS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVBdphmathu7"
      },
      "source": [
        "\n",
        "class MLROS:\n",
        "  def __init__(self):\n",
        "    self.labelsInDataset = []\n",
        "    self.instances=[]\n",
        "    self.features=[]\n",
        "\n",
        "  \"\"\"Retorna X e y reamostrados.\n",
        "\n",
        "  Entradas:\n",
        "  D = Dataframe com a base completa\n",
        "  X = Features de cada instância\n",
        "  y = Classes multirrótulo de cada instância\n",
        "  \"\"\"\n",
        "  def fit_resample(self,D,X,y,P):\n",
        "    #preparação das variáveis\n",
        "    samplesToClone = int((len(X)/100)*P)\n",
        "    print(samplesToClone)\n",
        "    _, labelList = getCaracteristicas(D)\n",
        "    self.labelsInDataset = np.arange(len(labelList))\n",
        "    self.instances = y.toarray()\n",
        "    #calculo da média de balanceamento\n",
        "    mean_ir= self.get_mean_imbalance_ratio()\n",
        "    if isinstance(X,np.ndarray):\n",
        "      self.features = X\n",
        "    else:\n",
        "      self.features = X.values\n",
        "    print(\"MeanIR Original: \",mean_ir)\n",
        "    #usando a média de balanceamento, achar qual as bags minoritárias\n",
        "    min_bags={}\n",
        "    for label in self.labelsInDataset:\n",
        "      print(f\"Fazendo bag da label {label}\")\n",
        "      irlbl=self.get_imbalance_ratio_per_label(label)\n",
        "      if irlbl > mean_ir:\n",
        "        min_bags[label] = self.get_all_instances_of_label(label)\n",
        "    while samplesToClone > 0:\n",
        "      #clone a random sample from each minority bag\n",
        "      for label in list(min_bags.keys()):\n",
        "        print(min_bags[label])\n",
        "        x = random.randint(1,len(min_bags[label]))\n",
        "        print(x)\n",
        "        self.features = np.insert(self.features,len(self.features),self.features[x],axis = 0)\n",
        "        self.instances = np.insert(self.instances,len(self.instances),self.instances[x],axis = 0)\n",
        "        if(self.get_imbalance_ratio_per_label(label)<=mean_ir):\n",
        "          min_bags.pop(label)\n",
        "        samplesToClone = samplesToClone - 1\n",
        "        clear_output(wait=True)\n",
        "        print(samplesToClone)\n",
        "    return np.array(self.features), csr_matrix(self.instances)\n",
        "        \n",
        "\n",
        "  def get_all_instances_of_label(self,label):\n",
        "    instance_ids=[]\n",
        "    append_instance_id=instance_ids.append\n",
        "    for i,label_set in enumerate(self.instances):\n",
        "      if(label_set[label] == 1):\n",
        "        append_instance_id(i)\n",
        "    return np.array(instance_ids)\n",
        "\n",
        "  def get_mean_imbalance_ratio(self):\n",
        "    ratio_sum=np.sum(np.array(list(map(self.get_imbalance_ratio_per_label,self.labelsInDataset))))\n",
        "    return ratio_sum/self.labelsInDataset.shape[0]\n",
        "\n",
        "  def get_imbalance_ratio_per_label(self,l):\n",
        "    sum_h_dataset=list(map(self.sum_h,self.labelsInDataset))\n",
        "    sum_h_dataset=np.array(sum_h_dataset)\n",
        "    return sum_h_dataset.max()/self.sum_h(l)\n",
        "\n",
        "  def sum_h(self,l): \n",
        "    h_sum=0\n",
        "    for label_set in self.instances: \n",
        "      h_sum += label_set[l] # se a instancia for da classe 'X', o array na posição 'X' sera 1, senão será 0\n",
        "    return h_sum\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_wVSts2MzE7"
      },
      "source": [
        "MLRUS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH011HBCM0TR"
      },
      "source": [
        "class MLRUS:\n",
        "  def __init__(self):\n",
        "    self.labelsInDataset = []\n",
        "    self.instances=[]\n",
        "    self.features=[]\n",
        "\n",
        "  \"\"\"Retorna X e y reamostrados.\n",
        "\n",
        "  Entradas:\n",
        "  D = Dataframe com a base completa\n",
        "  X = Features de cada instância\n",
        "  y = Classes multirrótulo de cada instância\n",
        "  \"\"\"\n",
        "  def fit_resample(self,D,X,y,P):\n",
        "    #preparação das variáveis\n",
        "    samplesToRemove = int((len(X)/100)*P)\n",
        "    print(samplesToRemove)\n",
        "    _, labelList = getCaracteristicas(D)\n",
        "    self.labelsInDataset = np.arange(len(labelList))\n",
        "    self.instances = y.toarray()\n",
        "    #calculo da média de balanceamento\n",
        "    mean_ir= self.get_mean_imbalance_ratio()\n",
        "    if isinstance(X,np.ndarray):\n",
        "      self.features = X\n",
        "    else:\n",
        "      self.features = X.values\n",
        "    print(\"MeanIR Original: \",mean_ir)\n",
        "    #usando a média de balanceamento, achar qual as bags majoritárias\n",
        "    max_bags={}\n",
        "    for label in self.labelsInDataset:\n",
        "      #clear_output(wait=True)\n",
        "      print(f\"Fazendo bag da label {label}\")\n",
        "      irlbl=self.get_imbalance_ratio_per_label(label)\n",
        "      if irlbl < mean_ir:\n",
        "        max_bags[label] = self.get_all_instances_of_label(label)\n",
        "    while samplesToRemove > 0:\n",
        "      #remover uma instancia de cada bag majoritária\n",
        "      for label in list(max_bags.keys()):\n",
        "        x = random.randint(1,len(max_bags[label]))\n",
        "        self.features = np.delete(self.features, x, axis=0)\n",
        "        self.instances = np.delete(self.instances, x, axis=0)\n",
        "        if(self.get_imbalance_ratio_per_label(label)>=mean_ir):\n",
        "          max_bags.pop(label)\n",
        "        samplesToRemove = samplesToRemove - 1\n",
        "        clear_output(wait=True)\n",
        "        print(samplesToRemove)\n",
        "    return np.array(self.features), csr_matrix(self.instances)\n",
        "        \n",
        "\n",
        "  def get_all_instances_of_label(self,label):\n",
        "    instance_ids=[]\n",
        "    append_instance_id=instance_ids.append\n",
        "    for i,label_set in enumerate(self.instances):\n",
        "      if(label_set[label] == 1):\n",
        "        append_instance_id(i)\n",
        "    return np.array(instance_ids)\n",
        "\n",
        "  def get_mean_imbalance_ratio(self):\n",
        "    ratio_sum=np.sum(np.array(list(map(self.get_imbalance_ratio_per_label,self.labelsInDataset))))\n",
        "    return ratio_sum/self.labelsInDataset.shape[0]\n",
        "\n",
        "  def get_imbalance_ratio_per_label(self,l):\n",
        "    sum_h_dataset=list(map(self.sum_h,self.labelsInDataset))\n",
        "    sum_h_dataset=np.array(sum_h_dataset)\n",
        "    return sum_h_dataset.max()/self.sum_h(l)\n",
        "\n",
        "  def sum_h(self,l): \n",
        "    h_sum=0\n",
        "    for label_set in self.instances: \n",
        "      h_sum += label_set[l] # se a instancia for da classe 'X', o array na posição 'X' sera 1, senão será 0\n",
        "    return h_sum\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn1anfj9Z_yC"
      },
      "source": [
        "MLSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9GzvgdZ-CL"
      },
      "source": [
        "class MLSMOTE:\n",
        "  def __init__(self,k):\n",
        "    self.k=k\n",
        "    self.labelsInDataset = []\n",
        "    self.instances=[]\n",
        "    self.features=[]\n",
        "\n",
        "  \"\"\"Retorna X e y reamostrados.\n",
        "\n",
        "  Entradas:\n",
        "  D = Dataframe com a base completa\n",
        "  X = Features de cada instância\n",
        "  y = Classes multirrótulo de cada instância\n",
        "  \"\"\"\n",
        "  def fit_resample(self,D,X,y,k):\n",
        "    print(X)\n",
        "    ##L <- labelsInDataset(D) > Full set of labels\n",
        "    _, labelList = getCaracteristicas(D)\n",
        "    self.labelsInDataset = np.arange(len(labelList))#np.unique(np.array([a for x in y for a in (x if isinstance(x, list) else [x])]))\n",
        "    self.instances = y.toarray()#np.array([np.array(xi) for xi in y])\n",
        "    ##MeanIR <- calculateMeanIR(D; L)\n",
        "    mean_ir= self.get_mean_imbalance_ratio()\n",
        "    if isinstance(X,np.ndarray):\n",
        "      self.features = X\n",
        "    else:\n",
        "      self.features = X.values\n",
        "    X_synth=[]\n",
        "    y_synth=[]\n",
        "    append_X_synth=X_synth.append\n",
        "    append_y_synth=y_synth.append\n",
        "    print(\"MeanIR Original: \",mean_ir)\n",
        "    ##for each label in L do\n",
        "    for label in self.labelsInDataset:\n",
        "      print(\"label: \",label)\n",
        "      ##IRLbllabel <- calculateIRperLabel(D; label)\n",
        "      irlbl=self.get_imbalance_ratio_per_label(label)\n",
        "      print(\"irplbl: \",irlbl)\n",
        "      print(' ')\n",
        "      ##if IRLbllabel > MeanIR then\n",
        "      if irlbl > mean_ir:\n",
        "        ##> Bags of minority labels samples\n",
        "        ##minBag <- getAllInstancesOfLabel(label)\n",
        "        min_bag=self.get_all_instances_of_label(label)\n",
        "        ##for each sample in minBag do\n",
        "        for sample in min_bag:\n",
        "          ##distances <- calcDistance(sample, minBag)\n",
        "          distances=self.calc_distances(sample,min_bag)\n",
        "          distances=np.sort(distances,order='distance')\n",
        "          neighbours=distances[1:k+1]\n",
        "          ref_neigh=np.random.choice(neighbours)\n",
        "          X_new,y_new=self.create_new_sample(sample,ref_neigh[1],[x[1] for x in neighbours])\n",
        "          append_X_synth(X_new)\n",
        "          append_y_synth(y_new)\n",
        "    X_synth = list(self.features) + list(X_synth)\n",
        "    y_synth = np.array(list(y.toarray()) + list(y_synth))\n",
        "    return np.array(X_synth),csr_matrix(np.array(y_synth))\n",
        "\n",
        "  def create_new_sample(self,sample_id,ref_neigh_id,neighbour_ids):\n",
        "    sample=self.features[sample_id]\n",
        "    sample_labels=self.instances[sample_id]\n",
        "\n",
        "    synth_sample=np.zeros(sample.shape[0])\n",
        "    ref_neigh=self.features[ref_neigh_id]\n",
        "    for i in range(synth_sample.shape[0]):\n",
        "      #if f is numeric todo:implement nominal support\n",
        "      diff=ref_neigh[i]-sample[i]\n",
        "      offset=diff*random.uniform(0,1)\n",
        "      synth_sample[i]=sample[i]+offset\n",
        "\n",
        "    neighbours_labels=[]\n",
        "    for ni in neighbour_ids:\n",
        "      neighbours_labels.append(self.instances[ni].tolist())\n",
        "    reference_labels = neighbours_labels\n",
        "    reference_labels.append(sample_labels.tolist())\n",
        "    labels=np.zeros(len(sample_labels))\n",
        "    #print(reference_labels)\n",
        "\n",
        "    \n",
        "    for j in range(0, len(labels)):\n",
        "      occurences = 0\n",
        "      for i in reference_labels:\n",
        "        if(i[j] == 1):\n",
        "          occurences += 1\n",
        "      if(occurences > (self.k+ 1)/2):\n",
        "        labels[j] = 1\n",
        "\n",
        "    y=labels\n",
        "    X=synth_sample\n",
        "    return X,y\n",
        "\n",
        "\n",
        "  def calc_distances(self,sample,min_bag):\n",
        "    distances=[]\n",
        "    append_distances=distances.append\n",
        "    for bag_sample in min_bag:\n",
        "      #if f is numeric todo:implement nominal support\n",
        "      # print('')\n",
        "      # print(self.features[sample])\n",
        "      # print(self.features[bag_sample])\n",
        "      # print('')\n",
        "      append_distances((np.linalg.norm(self.features[sample]-self.features[bag_sample]),bag_sample))\n",
        "    dtype =  np.dtype([('distance', float), ('index', int)])\n",
        "    return np.array(distances,dtype=dtype)\n",
        "\n",
        "  def get_all_instances_of_label(self,label):\n",
        "    instance_ids=[]\n",
        "    append_instance_id=instance_ids.append\n",
        "    for i,label_set in enumerate(self.instances):\n",
        "      if(label_set[label] == 1):\n",
        "        append_instance_id(i)\n",
        "    return np.array(instance_ids)\n",
        "\n",
        "  def get_mean_imbalance_ratio(self):\n",
        "    ratio_sum=np.sum(np.array(list(map(self.get_imbalance_ratio_per_label,self.labelsInDataset))))\n",
        "    return ratio_sum/self.labelsInDataset.shape[0]\n",
        "\n",
        "  def get_imbalance_ratio_per_label(self,l):\n",
        "    sum_h_dataset=list(map(self.sum_h,self.labelsInDataset))\n",
        "    sum_h_dataset=np.array(sum_h_dataset)\n",
        "    return sum_h_dataset.max()/self.sum_h(l)\n",
        "\n",
        "  def sum_h(self,l): \n",
        "    h_sum=0\n",
        "    for label_set in self.instances: \n",
        "      h_sum += label_set[l] # se a instancia for da classe 'X', o array na posição 'X' sera 1, senão será 0\n",
        "    return h_sum\n",
        "\n",
        "\n",
        "  def get_value_counts(self,labels):\n",
        "    count_map=np.array(np.unique(labels, return_counts=True)).T\n",
        "    counts=np.array([x[1] for x in count_map])\n",
        "    return counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JmptWmMqqek"
      },
      "source": [
        "# Consultar e formatar FMA Original\n",
        "Código sequencial para retornar a base FMA guardada no drive do ambiente e tratar ela para que seja usável nas próximas etapas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTPh7q9Hmzz3"
      },
      "source": [
        "Carregar e guardar variaves com informações sobre a base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r44b21fQFozm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7c4a31bd-70d9-41a8-c706-797177e72170"
      },
      "source": [
        "#Carregar base com todas as features\n",
        "features_df = pd.read_csv('drive/My Drive/TCC/fma_metadata/features.csv').drop([0, 1, 2])\n",
        "#Carregar base com todas as trilhas\n",
        "tracks = pd.read_csv('drive/My Drive/TCC/fma_metadata/tracks.csv')\n",
        "#Tirar colunas que não serão usadas e renomear as restantes\n",
        "track_genres = tracks[['Unnamed: 0','track.8']].drop([0,1]).rename(columns = {\"Unnamed: 0\": \"track_id\", \"track.8\" : \"genres\"})\n",
        "#Obter nomes dos generos existentes na base\n",
        "genres = pd.read_csv('drive/My Drive/TCC/fma_metadata/genres.csv')[['genre_id','title']]\n",
        "#Tratar gêneros nas trilhas para qu sejam formatados e fiquem compativeis com ferramentas SciKit, com uma coluna binária para cada gênero\n",
        "labels_df = track_genres.iloc[:,1].str.replace(' ','').str.replace('[','').str.replace(']','').str.get_dummies(sep=',')\n",
        "#Montar um dicionario dos gêneros para renomear colunas individuais para cada gênero\n",
        "dict_genres = {}\n",
        "for column in labels_df.columns:\n",
        "  dict_genres[column] = genres.loc[genres['genre_id'] == int(column)]['title'].values[0]\n",
        "labels_df = labels_df.rename(columns = dict_genres)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WERnN1Pym5d9"
      },
      "source": [
        "Quebrar a base em features e labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K74hNd1OeZnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a0eb4e00-f5d2-47d6-e929-191953c48f0f"
      },
      "source": [
        "dict_ft_names = {}\n",
        "ft_number = 0\n",
        "#Selecionar quais tipos de features serão usados, o artigo da FMA recomenda 4 e 8\n",
        "feature_types = []\n",
        "for x in features_df.columns:\n",
        "  feature_types.append(x.split('.')[0])\n",
        "feature_types = list(dict.fromkeys(feature_types))\n",
        "print(\"Quais tipos de features gostaria de usar?(em caso de multiplos, separar por espaço)\")\n",
        "print(\"1 - 'chroma_cens'\\n2 -'chroma_cqt'\\n3 -'chroma_stft\\n4 - 'mfcc'\\n5 - 'rmse'\\n6 - 'spectral_bandwidth'\\n7 - 'spectral_centroid'\\n8 - 'spectral_contrast'\\n9 - 'spectral_rolloff'\\n10 - 'tonnetz'\\n11 - 'zcr'\")\n",
        "features_input = input()\n",
        "#Obter somente os gêneros desejados\n",
        "list_of_features = []\n",
        "for i in features_input.split():\n",
        "  temp = [j for j in features_df.columns if feature_types[int(i)] in j]\n",
        "  list_of_features.append(temp)\n",
        "list_of_features = [item for sublist in list_of_features for item in sublist]\n",
        "list_of_features.insert(0,'feature')\n",
        "features_df = features_df[list_of_features]\n",
        "#renomear features e enumera-los. sendo o primeiro o feature0 até o ultimo featureX\n",
        "for column in features_df.columns:\n",
        "  dict_ft_names[column] = 'feature' + str(ft_number)\n",
        "  ft_number = ft_number + 1\n",
        "features_df = features_df.rename(columns = dict_ft_names)\n",
        "\n",
        "features_df = features_df.reset_index(drop=True)\n",
        "labels_df = labels_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quais tipos de features gostaria de usar?(em caso de multiplos, separar por espaço)\n",
            "1 - 'chroma_cens'\n",
            "2 -'chroma_cqt'\n",
            "3 -'chroma_stft\n",
            "4 - 'mfcc'\n",
            "5 - 'rmse'\n",
            "6 - 'spectral_bandwidth'\n",
            "7 - 'spectral_centroid'\n",
            "8 - 'spectral_contrast'\n",
            "9 - 'spectral_rolloff'\n",
            "10 - 'tonnetz'\n",
            "11 - 'zcr'\n",
            "4 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfEgGeum-2c"
      },
      "source": [
        "Finalizar as normalizações na base para ser usada juntamente ao SciKit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxTFnDJJqdFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bb4810ef-47ec-4c37-c353-8814ca7434f6"
      },
      "source": [
        "#Montar dataframe geral e forçar que todos os campos sejam numéricos, evitando erros nas ferramentas scikit\n",
        "df = pd.concat([features_df, labels_df], axis=1)\n",
        "for column in df:\n",
        "  df[column] =  pd.to_numeric(df[column], errors='coerce')\n",
        "\n",
        "#Cortar dataframe final em Features e Labels, cada linha representando uma trilha\n",
        "list_of_columns = df.columns.to_list()\n",
        "r = re.compile(\"feature.*\")\n",
        "features = list(filter(r.match, list_of_columns)) # Read Note\n",
        "features.remove('feature0')\n",
        "labels = (list(set(list_of_columns) - set(features)))\n",
        "labels.remove('feature0')\n",
        "#tirar generos com menos de X instâncias, 9 é o menor gênero existente na FMA\n",
        "df, labels = dropGenresWithLessThan(5, df)\n",
        "genderless_rows_to_drop = []\n",
        "for index, row in df.iterrows():\n",
        "    if(not row[labels].values.any()):\n",
        "      genderless_rows_to_drop.append(index)\n",
        "df = df.drop(genderless_rows_to_drop)\n",
        "#formatações finais para tirar colunas que não serão relevantes para a classificação (ID da musica)\n",
        "track_ids_df = df['feature0']\n",
        "df = df.drop(columns=['feature0'])\n",
        "#guardar base em X e y, pronto pra usar nas ferramentas SciKit\n",
        "myfunc_vec = np.vectorize(int)\n",
        "y = myfunc_vec(df[labels].values)\n",
        "y = csr_matrix(y)\n",
        "X = df[features]\n",
        "v = validatorB()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Minimal Electronic', 'Holiday', 'Progressive', 'Salsa', 'Bigbeat', 'Techno', 'Polka', 'Modern Jazz', 'Reggae - Dancehall', 'Jazz', 'Chiptune', 'Unclassifiable', 'Latin America', 'Abstract Hip-Hop', 'Chip Music', 'Loud-Rock', 'Trip-Hop', 'Thrash', 'New Age', 'Nerdcore', 'Chamber Music', 'Sound Collage', 'Sound Poetry', 'Psych-Folk', 'Skweee', 'Novelty', 'Compilation', 'Nu-Jazz', 'Instrumental', 'Hip-Hop', 'Improv', 'Surf', 'Kid-Friendly', 'Noise', 'Reggae - Dub', 'Free-Folk', 'Minimalism', 'Afrobeat', 'Singer-Songwriter', 'Symphony', 'Downtempo', 'Chill-out', 'Comedy', 'Sludge', 'Dance', 'Experimental Pop', 'Lo-Fi', 'Space-Rock', 'Lounge', 'Goth', 'Post-Punk', 'Glitch', 'Spanish', 'Free-Jazz', 'Noise-Rock', 'Alternative Hip-Hop', 'Easy Listening: Vocal', 'British Folk', 'Folk', 'Psych-Rock', 'Audio Collage', 'Garage', 'Freak-Folk', 'Celtic', 'Ambient', 'Drone', 'Gospel', 'Europe', 'Blues', 'Jazz: Out', 'Breakcore - Hard', 'Funk', 'Balkan', 'Drum & Bass', 'No Wave', 'Fado', 'Bluegrass', 'Soul-RnB', 'Turkish', 'Death-Metal', 'Interview', 'Power-Pop', 'Country & Western', 'Breakbeat', 'Radio', 'Americana', 'Wonky', 'Krautrock', 'Rock Opera', 'Electroacoustic', 'Jungle', 'Field Recordings', 'Metal', 'Country', 'Electro-Punk', 'Middle East', 'Synth Pop', 'Black-Metal', 'Spoken Word', 'Musique Concrete', 'Pop', 'Grindcore', 'Punk', 'Rockabilly', 'Dubstep', 'House', 'Spoken', 'Asia-Far East', 'Disco', 'Spoken Weird', 'North African', 'Classical', 'Tango', 'French', 'Soundtrack', 'Sound Effects', 'Cumbia', 'Flamenco', 'Klezmer', 'Christmas', 'Jazz: Vocal', 'Easy Listening', 'Avant-Garde', 'Opera', 'Brazilian', 'Hip-Hop Beats', 'Indie-Rock', 'Electronic', 'Sound Art', 'South Indian Traditional', 'Romany (Gypsy)', 'Radio Art', 'Composed Music', 'New Wave', 'Big Band/Swing', 'Old-Time / Historic', 'Hardcore', 'Rock', 'Banter', 'International', 'Talk Radio', 'Post-Rock', 'Indian', 'Poetry', 'African', 'Choral Music', 'Musical Theater', 'Contemporary Classical', 'Radio Theater', '20th Century Classical', 'Latin', 'Rap', 'IDM', 'Experimental', 'Ambient Electronic', 'Industrial', 'Pacific', 'Shoegaze']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6AAc9KXkBKx"
      },
      "source": [
        "Caracteristicas gerais da base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFP8KfDsIkF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0090b491-45c7-4ae0-c08c-7304448d4fa7"
      },
      "source": [
        "print(\"O numero de rótulos na base é:\", len(labels))\n",
        "print(\"A cardinalidade de rótulo é:\", cardinalidadeDeRotulo(df))\n",
        "print(\"A densidade de rótulo é:\", densidadeDeRotulo(df))\n",
        "#print(\"A média da razão de desbalanceamento (MeanIR) é:\", v.meanIR(y,df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O numero de rótulos na base é: 158\n",
            "A cardinalidade de rótulo é: 2.4329844537734586\n",
            "A densidade de rótulo é: 0.015398635783359307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7qbqON9V6di"
      },
      "source": [
        "#Balanceamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFM1KqnbaSxH"
      },
      "source": [
        "mlros = MLROS()\n",
        "X_train_MLROS, y_train_MLROS = mlros.fit_resample(df,X_train, y_train, 4.76)\n",
        "meanIR_MLROS = v.meanIR(y_train_MLROS, df)\n",
        "print(\"MeanIR resampled:\", meanIR_MLROS)\n",
        "print(f\"Tamanho Original:{len(X_train)}\")\n",
        "print(f\"Tamanho resampled:{len(X_train_MLROS)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf3HO6ClkUXx"
      },
      "source": [
        "Uso do MLRUS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ryZxB_aUWq"
      },
      "source": [
        "mlrus = MLRUS()\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train_MLRUS, y_train_MLRUS = mlrus.fit_resample(df,X_train, y_train, 5.26)\n",
        "meanIR_MLRUS = v.meanIR(y_train_MLRUS, df)\n",
        "print(\"MeanIR resampled:\", meanIR_MLRUS)\n",
        "print(f\"Tamanho Original:{len(X_train)}\")\n",
        "print(f\"Tamanho resampled:{len(X_train_MLRUS)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AhAGG6LkWQQ"
      },
      "source": [
        "Uso do MLSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byb85QZkbGan"
      },
      "source": [
        "mlsmote = MLSMOTE(3)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train_MLSMOTE, y_train_MLSMOTE = mlsmote.fit_resample(df,X_train, y_train, 3)\n",
        "meanIR_MLSMOTE = v.meanIR(y_train_MLSMOTE, df)\n",
        "print(\"MeanIR resampled:\", meanIR_MLSMOTE)\n",
        "print(f\"Tamanho Original:{len(X_train)}\")\n",
        "print(f\"Tamanho resampled:{len(X_train_MLSMOTE)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfOsrCiO3IRP"
      },
      "source": [
        "mlsmote = MLSMOTE(3)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train_MLROS_MLSMOTE, y_train_MLROS_MLSMOTE = mlsmote.fit_resample(df,X_train_MLROS, y_train_MLROS, 3)\n",
        "meanIR_MLROS_MLSMOTE = v.meanIR(y_train_MLROS_MLSMOTE, df)\n",
        "print(\"MeanIR resampled:\", meanIR_MLROS_MLSMOTE)\n",
        "print(f\"Tamanho Original:{len(X_train_MLROS)}\")\n",
        "print(f\"Tamanho resampled:{len(X_train_MLROS_MLSMOTE)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5i4FJOqt1sU"
      },
      "source": [
        "mlsmote = MLSMOTE(3)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train_MLRUS_MLSMOTE, y_train_MLRUS_MLSMOTE = mlsmote.fit_resample(df,X_train_MLRUS, y_train_MLRUS, 3)\n",
        "meanIR_MLRUS_MLSMOTE = v.meanIR(y_train_MLRUS_MLSMOTE, df)\n",
        "print(\"MeanIR resampled:\", meanIR_MLRUS_MLSMOTE)\n",
        "print(f\"Tamanho Original:{len(X_train_MLRUS)}\")\n",
        "print(f\"Tamanho resampled:{len(X_train_MLRUS_MLSMOTE)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFW59t7gMtY1"
      },
      "source": [
        "# Classificação\n",
        "Classificação da base original com MLkNN do SciKit multilearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz2hskKUPq3f"
      },
      "source": [
        "#slice in train and test then classify\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# train\n",
        "classifier = MLkNN(3, 1)\n",
        "#classifier = DecisionTreeClassifier(max_depth=3,random_state=42).fit(X_train,y_train.toarray())\n",
        "#classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True,random_state=42))\n",
        "#y_score = classifier.fit(X_train, y_train)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9YYRYFuPu-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7099e4c1-60eb-402b-b606-82a99b5db700"
      },
      "source": [
        "#metrics\n",
        "#sciMetricas(y_test, predictions)\n",
        "print(\"\")\n",
        "#minhasMetricas(df, y_test, predictions.toarray())\n",
        "\n",
        "print(metrics.f1_score(y_true=y_test, y_pred=predictions, average='micro'))\n",
        "\n",
        "#slice in train and test then classify\n",
        "#X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_resampled, y_resampled, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0.3024940100196036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVSiP_sjoffI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4aaa9ce-09d1-42f8-c19e-62e0ffd070c7"
      },
      "source": [
        "minhasMetricas(df, y_test, y_pred.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metrica exposta na proposta:\n",
            "Classifier precision score: 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix4RCymGMSCf"
      },
      "source": [
        "#ROC-AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JLAYqX7kn3C"
      },
      "source": [
        "Definição da ROC e a AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwd2m4sQ4BU"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\"\"\"Mostra na tela a ROC e a AUC, utilizando MLkNN(5, 1) como método de classíficação.\n",
        "\n",
        "Entradas:\n",
        "D = Dataframe com a base completa\n",
        "X = Features de cada instância\n",
        "y = Classes multirrótulo de cada instância\n",
        "\"\"\"\n",
        "def roc_auc(D, X, y):\n",
        "  classifier = MLkNN(5, 1)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  sciMetricas(y_test, y_pred)\n",
        "  minhasMetricas(df, y_test, y_pred.toarray())\n",
        "  y_pred_proba = classifier.predict_proba(X_test)\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  #get labels from df\n",
        "  list_of_columns = D.columns.to_list()\n",
        "  r = re.compile(\"feature.*\")\n",
        "  features = list(filter(r.match, list_of_columns)) # Read Note\n",
        "  if 'feature0' in features:\n",
        "    features.remove('feature0')\n",
        "  labels = (list(set(list_of_columns) - set(features)))\n",
        "  if 'feature0' in labels:\n",
        "    labels.remove('feature0')\n",
        "  for i in range(0, len(labels)):\n",
        "    fpr[i], tpr[i], _ = metrics.roc_curve(y_test.toarray()[:,i], y_pred_proba.toarray()[:, i])\n",
        "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
        "    lw = 2\n",
        "    plt.plot(fpr[i], tpr[i], color='darkorange', alpha = 0.1,\n",
        "            lw=lw)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Falso Positivos')\n",
        "    plt.ylabel('Verdadeiros Positivos')\n",
        "    #plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "  print(f\"AUC média: {sum(roc_auc.values())/len(roc_auc)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjGpmCHtRW4P"
      },
      "source": [
        "roc_auc(df, X_train_MLROS_MLSMOTE, y_train_MLROS_MLSMOTE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}